---
title: "Assignment4"
author: "wooseokYoon"
date: "2023-04-27"
output: 
  html_document: 
    highlight: tango
editor_options: 
  markdown: 
    wrap: 72
---

## Predicting Delayed Flights

항공기의 연착(delay) 여부를 예측하는 것은 항공사와 공항 등 항공기 운항과
관련된 주체들에게 매우 중요하다. 항공기의 연착에 따라 대체 항공기
이용료, 숙박 비용, 공항 사용료 등의 비용 발생이 매우 크기 때문이다.
FlightRecords.csv 파일은 2004년 1월동안 Washington, DC 지역으로부터 New
York City로 운행한 2201개의 항공기 운행 기록을 포함한다. 본 문제에서는
다음 7개의 변수를 사용하여 항공기의 연착 여부를 예측해 본다.

• dayweek: 운행 요일 (1: Mon, 2: Tue, ..., 7: Sun)

• deptime: 출발시각 (예: 1455 = 14시55분, 839: 8시39분)

• origin: 출발공항코드(DCA: Reagan Nation, IAD: Dulles, BWI:
Baltimore-Washington Int'l)

• dest: 도착공항코드(JFK: Kennedy, LGA: LaGuardia, EWR: Newark)

• carrier: 항공사코드(CO: Continental, DH: Atlantic Coast, DL: Delta,
MQ: American Eagle, OH: Comair, RU: Continental Express, UA: United, US:
USAirways)

• weather: 날씨 (0: OK, 1: Bad) • delay: 연착여부("delayed" or "ontime")

```{r message=FALSE}
# 사용할 패키지 추가
library(ggplot2)
library(scales)
library(psych)
library(rsample)
library(caret)
library(glmnet)
library(ROCR)
library(kernlab)
```

1.  **다음의 순서로 data preprocessing을 진행하자.**

-   **항공기 출발시각(deptime)이 6시 이전이거나 22시 이후인 데이터는
    빈도 수가 매우 적으므로 데이터셋에서 제외시킨다.**

```{r}
# 데이터 파일 읽기
FR <- read.csv("FlightRecords.csv")
str(FR)

# 연착을 예측하는데 사용되는 7개 변수만 추출
FR <- FR[,c(-1,-5,-6,-7,-11,-12)]
str(FR)

# 출발시각 조건에 맞는 데이터만 추출
FR <- subset(FR, 600 <= deptime & deptime < 2200)
str(FR)
```

-   수치값으로 표현되어 있는 출발시각을 6시부터 22시까지 각 시간대를
    나타내는 범주형 변수로 변환한다 (Hint: 원 데이터를 100으로 나눈 후
    정수값으로 내림. 그 후 factor로 변환)

```{r}
# daytime 변수를 시간대를 나타내는 factor로 변환
FR$deptime <- factor(floor(FR$deptime/100), levels = c(6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21), labels = c("6AM", "7AM", "8AM", "9AM", "10AM", "11AM", "0PM", "1PM", "2PM", "3PM", "4PM", "5PM", "6PM", "7PM", "8PM", "9PM"))
```

-   수치값으로 표현되어 있는 dayweek와 weather 변수를 factor로 변환한다.

```{r}
# dayweek 변수 factor로 변환
FR$dayweek <- factor(FR$dayweek, levels = c(1,2,3,4,5,6,7), labels = c("Mon", "Tue", "Wen", "Thu", "Fri", "Sat", "Sun"))

# weather 변수 factor로 변환
FR$weather <- factor(FR$weather, levels = c(0,1), labels = c("OK", "Bad"))
```

-   factor로 표현되어 있는 delay 변수가 가지는 level의 순서를 "ontime",
    "delayed" 순으로 변환한다 (logistic regression 수행 시에 연착하는
    경우를 P(X) = 1 로 만들기 위해서).

```{r}
# delay 변수의 level 순서 변경
FR$delay <- factor(FR$delay, levels = c("ontime", "delayed"))
```

2.  요일 별 연착비율, 출발 시간대 별 연착 비율, 출발 공항 별 연착비율,
    도착 공항 별 연착 비율, 항공사 별 연착비율, 날씨 별 연착 비율을 각각
    그래프로 시각화해보자. 어떤 특성을 관찰할 수 있는가?

```{r}
# 요일 별 연착 비율 시각화
ggplot(FR, aes(x=dayweek, fill = delay)) + geom_bar(position = "fill") + scale_y_continuous(labels = percent) + labs(y="Percent",  title = "
Delay rate by dayweek", subtitle = "January, 2004") + scale_fill_brewer(palette = "Set1")
```

**Answer) 요일 별 연착 비율을 살펴보면 토요일이 연착비율이 상대적으로
적어 토요일에 다른 연착요인이 있지 않을까 의심할 수 있다. 하지만
전체적으로 요일과 연착이 크게 상관있는 것처럼 보이지는 않는다.**

```{r}
# 출발 시간대 별 연착 비율 시각화
ggplot(FR, aes(x=deptime, fill = delay)) + geom_bar(position = "fill") + scale_y_continuous(labels = percent) + labs(y="Percent", title = "
Delay rate by deptime", subtitle = "January, 2004") + scale_fill_brewer(palette = "Set2")
```

**Answer) 출발 시간대 별 연착 비율에서는 3시대와 7시대는 매우 높은
연착율을 보여주고 있기에 이 시간대에 연착과 관련한 요인이 있지 않을까
생각해볼 수 있다.**

```{r}
# 출발 공항 별 연착 비율 시각화
ggplot(FR, aes(x=origin, fill = delay)) + geom_bar(position = "fill") + scale_y_continuous(labels = percent) + labs(y="Percent", title = "
Delay rate by origin", subtitle = "January, 2004") + scale_fill_brewer(palette = "Set3")

```

**Answer) 출발 공항 별 연착 비율은 세 공항 모두 비슷한 연착율이 나타나기
때문에 출발 공항과 연착의 관련이 커보이지 않는다.**

```{r}
# 도착 공항 별 연착 비율 시각화
ggplot(FR, aes(x=dest, fill = delay)) + geom_bar(position = "fill") + scale_y_continuous(labels = percent) + labs(y="Percent", title = "
Delay rate by dest", subtitle = "January, 2004") + scale_fill_brewer(palette = "Pastel2")
```

**Answer) 도착 공항 별 연착 비율도 마찬가지로 세 공항도 모두 비슷한
연착율로 보이기에 도착 공항과 연착의 관련성이 높아보이지 않는다.**

```{r}
# 항공사 별 연착 비율 시각화
ggplot(FR, aes(x=carrier, fill = delay)) + geom_bar(position = "fill") + scale_y_continuous(labels = percent) + labs(y="Percent", title = "
Delay rate by carrier", subtitle = "January, 2004") + scale_fill_brewer(palette = "Accent")
```

**Answer) 항공사 별 연착 비율은 DL, US, OH 항공사의 연착율이 매우 낮다는
것을 알 수 있다.**

```{r}
# 날씨 별 연착 비율 시각화
ggplot(FR, aes(x=weather, fill = delay)) + geom_bar(position = "fill") + scale_y_continuous(labels = percent) + labs(y="Percent", title = "
Delay rate by weather", subtitle = "January, 2004") + scale_fill_brewer(palette = "Pastel1")
```

**Answer) 날씨별 연착 비율은 가장 큰 영향인 것처럼 보이는데 날씨가 좋지
않을 때는 100%의 연착율을 보여주는 것으로 보아 날씨가 좋지 않은 경우
연착이 자주 일어남을 확인할 수 있다.**

3.  7개의 모든 변수들 간의 상관관계를 시각화해보자. 어떤 특성을 관찰할
    수 있는가?

```{r}
# feature 변수들 간의 상관관계 시각화
pairs.panels(FR[c("dayweek", "deptime", "origin", "dest", "carrier", "weather", "delay")])
```

**Answer) 상관관계가 가장 높은 경우는 carrier과 origin이고 그 때의
상관계수는 -0.40 정도로 그리 높지 않은 수치다. 즉, 각 feature들의
상관관계가 그리 높지 않다는 것을 확인할 수 있다.**

4.  데이터셋을 70:30 비율로 training set과 test set으로 분할하자. 이때
    stratified sampling을 활용하여 두 set에서 delay 변수의 분포가 크게
    차이가 없도록 분할하자.

```{r}
set.seed(77)
# stratified sampling을 통한 data set 분할
init_split <- initial_split(FR, prop = 0.7, strata = "delay")
FR_train <- training(init_split)
FR_test <- testing(init_split)

# 시각화를 위한 데이터프레임 생성
FR_train2 <- FR_train
FR_train2$setType <- "train"
FR_test2 <- FR_test
FR_test2$setType <- "test"
FR_sT <- rbind(FR_train2, FR_test2)

# train set과 test set의 delay 변수 비율
ggplot(FR_sT, aes(x= factor(setType, levels = c("train", "test")), fill = delay)) + geom_bar(position = "fill") + labs(x="Dataset Type", y = "Proportion")

# train set과 test set의 delay 변수 실제 개수 분포
ggplot(FR_sT, aes(x= factor(setType, levels = c("train", "test")), fill = delay)) + geom_bar(position = "dodge") + labs(x="Dataset Type")
```

5.  데이터시각화로부터 weather 변수가 "Bad" 인 경우에는 항상 항공기가
    연착되는 것을 관찰할 수 있다. 따라서 weather가 Bad이면 항공기가
    연착되고, weather가 OK일 경우 항공기가 연착되지 않는 것으로 예측하는
    단순한 모델을 baseline model이라 하자. Training set에 대해 baseline
    model을 적용했을 때의 confusion matrix를 계산해보자.

```{r}
# baseline model 생성
pred_base <- factor(FR_train$weather, levels = c("OK", "Bad"), labels = c("ontime", "delayed"))

# baseline model 적용 confusion matrix
confusionMatrix(pred_base, FR_train$delay, positive="delayed")
```

**Answer) 연착여부를 예측하는 모델이기에 Positive class는 delayed로
설정하였다. 82.3% 정도의 Accuracy를 가지며 이는 날씨가 괜찮을 때, 연착이
된 경우가 있기에 나타난 수치다. 민감도는 6.64% 정도로 낮게 나타났는데
이는 날씨가 안좋을 때보다 날씨가 괜찮을 때 실제 연착이 된 사건이 더 많이
일어났기에 나타난 수치다. 특이도가 100%인 이유는 날씨가 안좋을 때
제시간에 온 경우가 없기 때문에 나타난 수치다.**

6.  Training set을 대상으로, 연착여부(delay)를 나머지 모든 변수를
    사용하여 예측하기 위한 logistic regression model을 수립해보자.

```{r}
# target 변수를 제외한 모든 변수 사용 logistic regression model 생성
model_all = glm(delay~., data = FR_train, family = "binomial")
summary(model_all)
```

-   변수 deptime19의 regression coefficient에 대한 추정값은 얼마인가? 이
    추정값을 바탕으로 출발시각이 19시대인 항공기에 대해서 어떠한 해석을
    할 수 있는가? (Hint: 범주형 변수 deptime을 model에 추가할 때
    deptime6을 제외한 deptime7 \~ deptime21에 대한 dummy 변수가
    만들어진다.)

    **Answer) deptime7pm의 p-value 값으로 보아 통계적 유의성이 매우
    높다. 즉, 7pm에 움직이는 것이 연착에 영향을 끼친다고 볼 수 있다.**

-   날씨에 문제가 없는 목요일 15시에 IAD에서 출발하여 EWR로 도착한 Delta
    항공기가 연착될 확률은 얼마로 예측되는가?

```{r}
# 조건에 맞게 데이터프레임 수정
FR_example <- FR[1,]
FR_example[1, ] = c("DL", "3PM", "EWR", "IAD", "OK", "Thu", "delayed")
FR_example

# 확률 계산
prob_example <-  predict(model_all, newdata = FR_example, type = "response")
prob_example
```

**Answer) 위 조건의 연착을 할 확률은 약 0.2272의 확률을 갖는다.**

-   Threshold k = 0.3, 0.5, 0.7 에 대해서 각각 training set에 대한
    confusion matrix를 계산해 보자. 어떠한 경향을 관찰할 수 있는가?

```{r}
# Threshold가 0.3일 때, training set에 대한 model의 confusion matrix
prob_all = predict(model_all, type = "response")
pred_0.3 <- rep("ontime", 1511)
pred_0.3[prob_all > 0.3] <- "delayed"
confusionMatrix(factor(pred_0.3, levels = c("ontime", "delayed")), FR_train$delay, positive = "delayed")

# Threshold가 0.3일 때, training set에 대한 model의 confusion matrix
pred_0.5 <- rep("ontime", 1511)
pred_0.5[prob_all > 0.5] <- "delayed"
confusionMatrix(factor(pred_0.5, levels = c("ontime", "delayed")), FR_train$delay, positive = "delayed")

# Threshold가 0.3일 때, training set에 대한 model의 confusion matrix
pred_0.7 <- rep("ontime", 1511)
pred_0.7 [prob_all > 0.7] <- "delayed"
confusionMatrix(factor(pred_0.7, levels = c("ontime", "delayed")), FR_train$delay, positive = "delayed")
```

**Answer)**

|             | 0.3     | 0.5     | 0.7     |
|-------------|---------|---------|---------|
| Accuracy    | 0.8015  | 0.8432  | 0.8273  |
| Sensitivity | 0.44755 | 0.20979 | 0.09091 |
| Specificity | 0.88408 | 0.99102 | 0.99918 |

**표를 보면 Accuracy 측면에서 Threshold가 0.5일 때가 가장 높은 결과가
나타난다. Threshold가 0.3일 때는 상대적으로 Sensitivity가 높고
Specificity가 낮다. 반대로 Threshold가 0.7일 때는 상대적으로
Sensitivity가 높고 Specificity가 낮다. 이유는 Threshold가 0.3인 경우는
연착으로 판정하는 경우가 많아지고 Threshold 0.7일 때는 연착이 아니라고
판정하는 경우가 많기 때문이다.**

-   위의 결과를 바탕으로 Baseline model과 logistic regression model의
    성능을 비교해보자.

    **Baseline model의 비교 대상으로 Accuracy가 가장 높은 Threshold가
    0.5인 logistic regression model을 선정했다. Accuracy 측면에서
    82.33%에서 84.32%로 약 2% 증가했다. Sensitivity는 6.6%에서 21%로
    증가했는데 연착이 일어날 것을 예측하는 모델에서는 정확도도
    중요하지만 실제 연착 중에 연착이라고 예측하는 능력이 요하기 때문에
    더 좋은 모델이라고 판단된다. specificity는 줄어들었지만 0.9% 정도
    감소로 미미하다고 할 수 있다.**

7.  Training set을 대상으로 Lasso regression을 적용하여 logistic
    regression model을 수립해보자. CV의 결과 바탕으로 모델에 포함되는
    feature의 수와 예측정확도를 모두 고려했을 때 가장 적합한 모델을
    선택하자.

```{r}
# model의 feature matrix 생성
trainX <- model.matrix(delay~., data=FR_train)[,-1]

# model의 target vector 생성
trainY <- FR_train$delay

# AUC 값을 기준으로 cross validation 수행하면서 Lasso Regression 적용
set.seed(77)
cv_lasso <- cv.glmnet(x=trainX, y=trainY, alpha=1, family="binomial", type.measure = "auc", nfolds = 10)

# lambda 따른 AUC 변화
plot(cv_lasso)

# AUC가 최대가 되는 lambda의 값
cv_lasso$lambda.min

# 위 lambda.min 값을 이용시 포함된 변수
coef(cv_lasso, s=cv_lasso$lambda.min)

# 1-se rule을 적용한 lambda의 값
cv_lasso$lambda.1se

# lambda.1se 값을 이용시 포함된 변수
coef(cv_lasso, s=cv_lasso$lambda.1se)
```

-   어떠한 기준으로 모델을 선택하였으며, 최종적으로 모델에 어떠한
    변수들이 포함되었는가?

**Answer)**

**AUC를 기준으로 모델을 선택하였다.**

**최종 모델은 lambda로 lambda.1se 값을 사용한 모델로 선정하였다. AUC가
가장 높은 lambda.min값을 이용한 모델보다는 1se rule을 이용한 model이
그래프를 살펴보면 AUC는 비슷하지만 feature의 수가 더 적고 단순한
모델이라고 판단하였기에 선정하였다.**

**최종 모델의 feature의 개수는 11개이며 carrierDL, carrierRU, carrierUS,
deptime8AM, deptime0PM, deptime3PM, deptime7PM, deptime8PM, weatherBad,
dayweekSat, dayweekSun이 포함되었다.**

-   기본 logistic regression model과 Lasso를 적용한 logistic regression
    model의 성능을 나타내는 ROC Curve를 하나의 그래프로 시각화하고,
    AUC값을 비교해 보자. Lasso regression의 효과가 있다고 말할 수
    있는가? (training set과 test set에 대해서 각각 비교해보자.)

```{r}
# 기본 logistic model로 training set 연착 확률 계산
train_prob1 <- predict(model_all, type = "response")
head(train_prob1)

# 확률을 통해 연착 여부 예측
train_pred1 <- prediction(train_prob1, FR_train$delay, c("ontime", "delayed"))

# 예측의 성능을 평가하고 tpr을 y축, fpr을 x축으로 사용
train_perf1 <- performance(train_pred1, measure = "tpr", x.measure = "fpr")

# AUC 값 계산
auc_train1 <- performance(train_pred1, measure = "auc")
auc_train1@y.values

# lasso를 적용한 logistic model로 training set 연착 확률 계산
train_prob2 <- predict(cv_lasso, newx = model.matrix(delay~., data=FR_train)[,-1], s=cv_lasso$lambda.1se, type = "response")

# 확률을 통해 연착 여부 예측
train_pred2 <- prediction(train_prob2, FR_train$delay, c("ontime", "delayed"))

# 예측의 성능을 평가하고 tpr을 y축, fpr을 x축으로 사용
train_perf2 <- performance(train_pred2, measure = "tpr", x.measure = "fpr")

# AUC 값 계산
auc_train2 <- performance(train_pred2, measure = "auc")
auc_train2@y.values

# ROC curve 시각화
plot(train_perf1, col = "darkred", lwd = 3)
text(0.7, 0.5, paste0("기본 model : AUC = ", round(as.numeric(auc_train1@y.values), 3)), col = "darkred", cex = 1)
plot(train_perf2, col = "blue", lwd = 3, add = TRUE)
text(0.7, 0.4, paste0("Lasso 적용 model : AUC = ", round(as.numeric(auc_train2@y.values), 3)), col = "blue", cex = 1)
title("Training set에 대한 model AUC 비교")
```

**Answer) training set에 대한 기본 logistic regression model의 AUC는
0.756이고 lasso 적용 logistic regression model의 AUC는 0.734이다.
feature수가 많은 기본 model의 AUC가 예상대로 더 높긴 했지만 feature의
수를 11개로 줄인 Lasso model의 AUC와 큰 차이를 보이지는 않는다.**

```{r}
# 기본 logistic model로 test set 연착 확률 계산
test_prob1 <- predict(model_all, FR_test, type = "response")
head(test_prob1)

# 확률을 통해 연착 여부 예측
test_pred1 <- prediction(test_prob1, FR_test$delay, c("ontime", "delayed"))

# 예측의 성능을 평가하고 tpr을 y축, fpr을 x축으로 사용
test_perf1 <- performance(test_pred1, measure = "tpr", x.measure = "fpr")

# AUC 값 계산
auc_test1 <- performance(test_pred1, measure = "auc")
auc_test1@y.values

# lasso를 적용한 logistic model로 test set 연착 확률 계산
test_prob2 <- predict(cv_lasso, newx = model.matrix(delay~., data=FR_test)[,-1], s=cv_lasso$lambda.1se, type = "response")

# 확률을 통해 연착 여부 예측
test_pred2 <- prediction(test_prob2, FR_test$delay, c("ontime", "delayed"))

# 예측의 성능을 평가하고 tpr을 y축, fpr을 x축으로 사용
test_perf2 <- performance(test_pred2, measure = "tpr", x.measure = "fpr")

# AUC 값 계산
auc_test2 <- performance(test_pred2, measure = "auc")
auc_test2@y.values

# ROC curve 시각화
plot(test_perf1, col = "darkred", lwd = 3)
text(0.7, 0.5, paste0("기본 model : AUC = ", round(as.numeric(auc_test1@y.values), 3)), col = "darkred", cex = 1)
plot(test_perf2, col = "blue", lwd = 3, add = TRUE)
text(0.7, 0.4, paste0("Lasso 적용 model : AUC = ", round(as.numeric(auc_test2@y.values), 3)), col = "blue", cex = 1)
title("Test set에 대한 model AUC 비교")
```

**Answer)** **test set에 대한 기본 logistic regression model의 AUC는
0.740이고 lasso 적용 logistic regression model의 AUC는 0.715이다. 원
data set은 같더라도 training set과 test set이 데이터의 차이가 분명히
존재할 것이라고 예상하여 AUC의 감소가 꽤 클 것으로 예상했지만 예상보다는
낮은 감소폭을 보여줬다. 또한 test set에 대한 두 model의 AUC 차이는 크지
않다.**

**Lasso regression의 효과는 분명히 나타났다고 보여진다. feature의 수를
많이 줄였음에도 비슷한 각 data set에 대한 AUC의 차이는 크지 않았다. 그에
반해 모델의 해석용이성은 큰 차이가 날 것으로 예상된다.**

8.  Training set을 대상으로 k-nn을 적용해보자. 이때 cross validation으로
    Accuracy가 가장 높은 best k 값을 찾는다. best k 값은 얼마인가?

```{r}
# training set을 대상으로 k-nn 적용.
cv <- trainControl(method="repeatedcv", number = 10, repeats = 5)
tune_grid <- expand.grid(k = seq(1,31,2))

# training set을 대상으로 k-nn 적용.
knn_fit <- train(delay~., data = FR_train, method = "knn", trControl = cv, tuneGrid=tune_grid)
knn_fit

# k에 따른 정확도 시각화
ggplot(knn_fit)
```

**Answer) 모든 feature들이 factor와 문자형 형태이기에 스케일링은 따로
진행하지 않았다. 가장 정확도가 높은 best k 값은 3이며 Accuracy는
0.8154950로 나타난다.**

9.  Training set을 대상으로 SVM을 적용해보자. RBF Kernel을 활용하고,
    cross validation으로 Accuracy가 가장 높은 파라미터의 조합을 찾는다.
    어떤 파라미터 값을 사용했을 때 RBF Kernel의 CV 성능이 가장 좋은가?

```{r}
set.seed(77)
# Training set을 대상으로 RBF kernel 활용 svm 실시.
rbf_cv <- train(delay~., data=FR_train, method = "svmRadial", trControl = trainControl(method="repeatedcv", number = 10, repeats = 5), tuneGrid = expand.grid(sigma = 10^(-3:3), C = 10^(-3:3)))

# 파라미터 값에 따른 Accuracy 결과
rbf_cv

# 결과 시각화
plot(rbf_cv)
```

**Answer) sigma, 즉 gamma가 0.001이고 C가 1000인 파라미터 값을 가질 때,
Accuracy가 0.8536077로 나타난다.**

10. 지금까지 찾은 logistic regression, k-nn, svm model들에 대해서, test
    set에 대한 성능을 비교해보자. (최종 모델을 선택하기 위해 test set을
    사용하는 것은 아니다. 단순히 세 가지 다른 모델의 성능을 비교하는
    것이 목적이다.)

```{r}
# test set에 대한 기본 logistic regression model 성능 확인
logi_test_prob = predict(model_all, newdata = FR_test, type = "response")
logi_test_pred <- rep("ontime", 648)
logi_test_pred[logi_test_prob > 0.5] <- "delayed"
confusionMatrix(factor(logi_test_pred, levels = c("ontime", "delayed")), FR_test$delay, positive = "delayed")

# test set에 대한 lasso 적용 logistic regression model 성능 확인
lasso_test_prob <- predict(cv_lasso, newx = model.matrix(delay~., data=FR_test)[,-1], s=cv_lasso$lambda.1se, type = "response")
lasso_test_pred <- rep("ontime", 648)
lasso_test_pred[lasso_test_prob > 0.5] <- "delayed"
confusionMatrix(factor(lasso_test_pred, levels = c("ontime", "delayed")), FR_test$delay, positive = "delayed")

# test set에 대한 knn model 성능 확인
knn_test_pred <- predict(knn_fit, FR_test[,-7])
confusionMatrix(knn_test_pred, FR_test$delay, positive = "delayed")

# test set에 대한 RBF kernel svm model 성능 확인
svm_test_pred <- predict(rbf_cv, FR_test)
confusionMatrix(svm_test_pred, FR_test$delay, positive = "delayed")
```

**Answer)**

|             |                     |                           |         |         |
|-------------|--------------|-------------------|-------------|-------------|
|             | logistic regression | Lasso logistic regression | KNN     | SVM     |
| Accuracy    | 0.838               | 0.8302                    | 0.821   | 0.8503  |
| Sensitivity | 0.21138             | 0.10569                   | 0.19512 | 0.42276 |
| Specificity | 0.98476             | 1.00000                   | 0.96762 | 0.95048 |

**표에 결과를 종합해보면 data set의 특성상 Specificity가 전체적으로 높게
측정되었다.**

**model의 성능 측면에서 SVM model은 Accuracy 측면에서도 가장 높은 수치를
나타냈고 특히나 Sensitivity 측면에서는 다른 model에 비해 압도적으로 높은
수치가 나타났다. 이런 측면에서 볼 때, SVM model이 상대적으로 성능이
좋다는 결론을 내렸다.**
