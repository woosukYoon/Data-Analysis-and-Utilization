---
title: "Assignment2"
author: "wooseokYoon"
date: "2023-03-26"
output: html_document
---

<br/>
제목 : Assignment_2, 작성자 : 20192237 윤우석
<br/>

문제 상황 :
Common Bank는 현재 예금계좌 소유 고객을 대상으로 개인 대출 상품의 가입을 홍보하기 위한 마케팅을 준비중이다. 
마케팅 부서에서는 어떤 그룹의 고객들을 타겟팅하여 집중적으로 마케팅 예산을 투입할 지를 고민 중이다. 
따라서 k-NN을 활용하여 새로운 고객의 정보가 주어졌을 때 이 고객이 개인 대출 상품을 가입할 지를 예측해 보고자 한다. 

```{r message=FALSE}
# 사용할 패키지 추가
library(dplyr)
library(ggplot2)
library(class)
library(caret)
```

<br/>
1. 먼저 ID와 ZIP.code는 feature에서 제외한다. 그리고 z-score normalization을 활용하여 feature들의 scale을 일치시킨다. 첫 4,000명의 데이터를 training set으로, 나머지 1,000명의 데이터를 test set으로 사용하고, training set과 test set에서의 target variable의 분포를 비교해 보자.
<br/>

```{r}
#데이터 파일 불러오기
CB <- read.csv("CommonBank.csv")
str(CB)

# ID와 ZIP.code는 feature에서 제외.
CB <- CB[,c(-1,-5)]

# target variable인 PersonalLoan을 첫번째 열로 배치
CB <- CB %>% relocate(PersonalLoan)
str(CB)

# target variable을 factor 형식으로 변환 및 라벨링
CB$PersonalLoan <- factor(CB$PersonalLoan, levels = c(1,0), labels = c("Accept", "Reject"))

# z-score normalization 함수 정의
z_normalize <- function(x) {
 return ((x - mean(x)) / sd(x))
}

# 독립변수 scaling
CB_n <- as.data.frame(lapply(CB[2:12], z_normalize))
str(CB_n)

# train set과 test set의 데이터 할당.
CB_train <- CB_n[1:4000, ]
CB_test <- CB_n[4001:5000, ]

# train set과 test set의 종속변수 값 할당.
CB_train_labels <- CB[1:4000, 1]
CB_test_labels <- CB[4001:5000, 1]


# train set의 target variable 분포
table(CB_train_labels)

# test set의 target variable 분포
table(CB_test_labels)

# table을 datafrmae 형식으로 변환
df1 <- data.frame(table(CB_train_labels))
df2 <- data.frame(table(CB_test_labels))

# 열이름을 맞춘 후 행방향으로 합침
colnames(df1)[1] <- "PersonalLoan"
colnames(df2)[1] <- "PersonalLoan"
df_tv <- rbind(df1, df2)

# train set과 test set을 나누는 factor 요소 추가
train_test <- factor(c("train", "train", "test", "test"))
df_tv$train_test <- train_test
str(df_tv)

# 막대 그래프로 시각화
p1 <- ggplot(df_tv, aes(x= train_test, y=Freq, fill = PersonalLoan)) + geom_bar(stat = "identity", position = "dodge")
p1

```
<br/>
2. 7-NN을 적용하고, 결과를 분석해보자.
<br/>

```{r}

# k를 7로 knn 진행
CB_test_pred <- knn(train = CB_train, test = CB_test, cl = CB_train_labels, k=7)

# 결과 분석
confusionMatrix(CB_test_pred, CB_test_labels)
```

<br/>
3. Training set 중에서 마지막 800명의 데이터를 validation set으로 사용하여, 다양한 k 값에 대해 k-NN을 적용해 보고 예측 성능을 비교해 보자. k가 어떤 값을 가질때 모델의 성능이 가장 우수한가?
<br/>

```{r}
# train set과 validation set의 데이터 할당.
CB_train <- CB_n[1:3200, ]
CB_valid <- CB_n[3201:4000, ]

# train set과 validation set의 종속변수 값 할당.
CB_train_labels <- CB[1:3200, 1]
CB_valid_labels <- CB[3201:4000, 1]

# vector 변수 지정
K = vector()
Accuracy = vector()

# k에 따른 모델의 Accuracy를 측정한 후 그 결과 값을 dataframe에 추가
for(i in seq(1, 31, by=2)){
  CB_test_pred <- knn(train = CB_train, test = CB_valid, cl = CB_train_labels, k=i)
  model_pred <- confusionMatrix(CB_test_pred, CB_valid_labels)
  K <- append(K, i)
  Accuracy <- append(Accuracy, model_pred$overall[1])
  df_Accuracy <- data.frame(K, Accuracy)
}
df_Accuracy

# k에 따른 모델의 Accuracy 변화 그래프로 시각화
p3 <- ggplot(df_Accuracy, aes(x=K, y=Accuracy)) + geom_line() + geom_point() + theme_bw()
p3
```

K가 1일 때, 모델의 성능이 가장 좋다는 것을 알 수 있다.


<br/>
4. Training set에 대해 5-fold cross validation을 5회 반복하여 best k 값을 찾아보자. Best k 값으로 만들어지는 최종 model에 test set을 적용하여 model의 성능을 report하자.
<br/>

```{r}
# z-normalized를 하기 전 데이터로 train set과 test set 분할
CB_train <- CB[1:4000, ]
CB_test <- CB[4001:5000, ]

# scaling 방식 변수 할당
z_normalized <- c("center", "scale")

# 5-fold cross validation 5회 반복 변수 할당
cv <- trainControl(method="repeatedcv", number = 5, repeats = 5)

# k의 값 변화를 변수 지정
tune_grid <- expand.grid(k = seq(1, 31, 2))

# 모델 train 이후 validation set을 이용한 k 값에 따른 모델 성능 검증 및 파악
knn_fit <- train(data=CB_train, PersonalLoan~., method="knn", trControl = cv, preProcess = z_normalized, tuneGrid = tune_grid)
knn_fit

# k에 따른 Accuracy 변화 그래프로 시각화
ggplot(knn_fit) + theme_bw()

# best k값으로 만들어진 최종 모델로 test set 적용시, 모델의 성능
test_pred <- predict(knn_fit, CB_test[,-1]) 
confusionMatrix(test_pred, CB_test_labels, positive = "Accept")
```

k가 3일 때, 가장 성능이 좋은 모델이 되고 그 때에 test set에 대한 모델의 성능은 Accuracy : 0.967이다.

<br/>
5. 3번과 4번에서 활용한 training 방식의 장단점을 비교해보자.
<br/>

3번의 장점은 4번에 비해 훈련 속도가 빠르다는 장점이 있다. 
단점으로는 특정 validation set을 이용하기 때문에 과적합이 된다. 즉, 모델이 매우 변화되기 쉽고, 비현실적이다.
<br/>
4번은 여러 train set에서 k-fold cross-validaiton을 이용하면서 train set과 validation set을 변화해가면서 자료 추출의 균일성을 확보했다고 볼 수 있다. 
즉, 4번 모델은 상대적으로 일반화된 성능을 가질 수 있으며 그로 인해 안정적이다.
단점으로는 3번에 비해 훈련 속도가 느리다는 단점이 있다.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
